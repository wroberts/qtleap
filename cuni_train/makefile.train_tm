SHELL=/bin/bash

LRC=0

ML_METHOD=maxent
#ML_METHOD=vw
#ML_METHOD=static

##################### dirs and aux files ############################

#DATA=???

SCRIPT_DIR=../tm_train
#TMP_DIR=/COMP.TMP/train_tm_$$$$
#SORT_TMP_DIR=$(TMP_DIR)/sort
SORT_TMP_DIR_PATTERN=$(TMP_DIR)/sort_XXXXX
TRAIN_LOG_DIR=$(TMP_DIR)/log.train_tm

SORTED_DATA=$(TMP_DIR)/tm_train_table.sorted.gz
DATA_SPLIT_DIR=$(TMP_DIR)/tm_data_split
DATA_SPLIT_LIST=$(DATA_SPLIT_DIR)/list
MODEL_SPLIT_DIR=$(TMP_DIR)/tm_model_split.$(ML_METHOD)
TRANSL_MODEL_LRC1=$(TMP_DIR)/model.$(ML_METHOD).lrc1.gz
TRANSL_MODEL_LRC0=$(TMP_DIR)/model.$(ML_METHOD).lrc0.gz
TRANSL_MODEL=$(TMP_DIR)/model.$(ML_METHOD).gz

###################### ML parameters #############################

LINES_PER_PART=500000
INSTANCES=10000
MIN_INSTANCES=100
#MIN_INSTANCES=10
MIN_PER_CLASS=5
CLASS_COVERAGE=1
SMOOTH_SIGMA=0.99
#FEATS=transl_mt
FEAT_CUT=2
#FEAT_WEIGHT_CUT=0.4
FEAT_COL=2

include makefile.config

ifeq ($(ML_METHOD), maxent)
ifdef FEAT_WEIGHT_CUT
	FEAT_WEIGHT_CUT_FLAG = -w $(FEAT_WEIGHT_CUT)
endif
	PARAMS_BASH := --feature_column $(FEAT_COL) -f $(FEAT_CUT) $(FEAT_WEIGHT_CUT_FLAG) -p 'smooth_sigma $(SMOOTH_SIGMA)'
endif
ifeq ($(ML_METHOD), vw)
	PARAMS_BASH := --feature_column $(FEAT_COL) -w 0.05
endif

TRANSL_MODEL_LRC_DEP=$(TRANSL_MODEL_LRC0)
ifeq ($(LRC),1)
	TRANSL_MODEL_LRC_DEP=$(TRANSL_MODEL_LRC1)
endif

######################### processing ###################################

train_tm : $(TRANSL_MODEL)

sort : $(SORTED_DATA)
$(SORTED_DATA) : $(DATA)
	@bin/log.sh INFO "Sorting the training data: $(DATA) => $(SORTED_DATA)" >&2
	sort_tmp_dir=`mktemp -d $(SORT_TMP_DIR_PATTERN)`; \
	zcat $< | sort -k1,1 -S 2G -T $$sort_tmp_dir | gzip -c  > $@; \
	rm -rf $$sort_tmp_dir

$(DATA_SPLIT_LIST) : $(SORTED_DATA)
	@bin/log.sh INFO "Splitting the sorted training data by a source label: $(SORTED_DATA) => $(DATA_SPLIT_LIST)" >&2
	mkdir -p $(DATA_SPLIT_DIR)
	zcat $< | $(SCRIPT_DIR)/split_on_value.pl $(LINES_PER_PART) $(DATA_SPLIT_DIR)/part
	find $(DATA_SPLIT_DIR) -name "part*" | sort | sed 's|$(DATA_SPLIT_DIR)/||' > $@
$(TRANSL_MODEL_LRC1) : $(DATA_SPLIT_LIST)
	@bin/log.sh INFO "Training partial TMs on cluster: $(DATA_SPLIT_LIST) => $(MODEL_SPLIT_DIR)/" >&2
	mkdir -p $(MODEL_SPLIT_DIR)
	DATA_SPLIT_SIZE=`cat $(DATA_SPLIT_LIST) | wc -l`
	mkdir -p $(TRAIN_LOG_DIR)/train_tm.output
	DATA_SPLIT_LIST="$(DATA_SPLIT_LIST)" \
	DATA_SPLIT_DIR="$(DATA_SPLIT_DIR)" \
	MODEL_SPLIT_DIR="$(MODEL_SPLIT_DIR)" \
	SCRIPT_DIR="$(SCRIPT_DIR)" \
	ML_METHOD="$(ML_METHOD)" \
	INSTANCES="$(INSTANCES)" \
	MIN_INSTANCES="$(MIN_INSTANCES)" \
	MIN_PER_CLASS="$(MIN_PER_CLASS)" \
	CLASS_COVERAGE="$(CLASS_COVERAGE)" \
	PARAMS_BASH="$(PARAMS_BASH)" \
	               qsub -t 1:$(DATA_SPLIT_SIZE) \
	               -j y \
	               -cwd \
	               -V \
	               -S /home/anglistik/robertsw/local-clou/bin/bash \
	               -o $(TRAIN_LOG_DIR)/train_tm.output \
	               -N train_tm \
	               -hard -l h_vmem=16g \
	               -p -100 \
	               qsubmit2
	while [ `ls $(MODEL_SPLIT_DIR)/done.* 2> /dev/null | wc -l` -lt `cat $< | wc -l` ]; do \
		sleep 5; \
    done; \
	rm $(MODEL_SPLIT_DIR)/done.*
	@bin/log.sh INFO "Merging partial TMs: $(MODEL_SPLIT_DIR)/ => $(TRANSL_MODEL)" >&2
	$(SCRIPT_DIR)/merge_models.pl $(ML_METHOD) $(MODEL_SPLIT_DIR) $@

$(TRANSL_MODEL_LRC0) : $(SORTED_DATA)
	@bin/log.sh INFO "Training the TM: $(SORTED_DATA) => $(TRANSL_MODEL)/" >&2
	zcat $< | $(SCRIPT_DIR)/train.pl \
		$(ML_METHOD) \
		-i $(INSTANCES) -m $(MIN_INSTANCES) \
		--min_per_class $(MIN_PER_CLASS) --class_coverage $(CLASS_COVERAGE) \
		$(PARAMS_BASH) \
		$@

.INTERMEDIATE : $(TRANSL_MODEL_LRC1) $(TRANSL_MODEL_LRC0)

$(TRANSL_MODEL) : $(TRANSL_MODEL_LRC_DEP)
	cp $(TRANSL_MODEL_LRC_DEP) $(TRANSL_MODEL)
